#!/bin/bash
# version 0.1
set -e

# TODO

# Pre run
echo "disable ipv6"
cat << SSHEOF >> /etc/sysctl.conf
#disable ipv6  
net.ipv6.conf.all.disable_ipv6 = 1  
net.ipv6.conf.default.disable_ipv6 = 1   
net.ipv6.conf.lo.disable_ipv6 = 1  
SSHEOF
sysctl -p
apt-get update
apt-get install -y openjdk-7-jdk
apt-get install -y ntpdate
apt-get install -y parted
apt-get install -y xmlstarlet pdsh
service ssh start

# download something from SF.net here
#wget http://prdownloads.sourceforge.net/drbl-hadoop/drbl-live-hadoop_0.2.tar.gz -O /opt/drbl-live-hadoop_0.2.tar.gz
#tar -zxvf /opt/drbl-live-hadoop_0.2.tar.gz -C /opt/

# basic variables
HADOOP_TEMP_CONF="/opt/drbl-live-hadoop-tmpl-conf"
HADOOP_RUN_USER="hadmin"
HADOOP_SOURCE="/opt/hadoop-2.3.0.tar.gz"

# hadoop related path
HADOOP_PATH="/usr/local/hadoop/"
HADOOP_CONF=$(echo -n "$HADOOP_PATH/etc/hadoop/")
HADOOP_TMP_DIR="/media/hadoop_data/tmp/"
HADOOP_NAMENODE_DIR="/media/hadoop_data/namenode/"
HADOOP_DFS_DATA_DIR="/media/hadoop_data/data/"
HADOOP_LOG4J_DIR="/media/hadoop_data/log/"
HADOOP_ENV_NATIVE_PATH="$HADOOP_PATH/lib/native"
HADOOP_ENV_OPTS="\"-Djava.library.path=$HADOOP_PATH/lib\""
JAVAHOME=$(ls -l /etc/alternatives/java | awk {'print $11'} | sed s/jre.*//g)

# update hostname
NAMENODE_HOSTNAME=$(hostname)
SECNODE_HOSTNAME=$(hostname)

# directories and key for hadoop user
su $HADOOP_RUN_USER -c 'ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa'
su $HADOOP_RUN_USER -c 'cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys'
cat << EOF >> /home/$HADOOP_RUN_USER/.ssh/config
Host *
    StrictHostKeyChecking no
    UserKnownHostsFile=/dev/null
EOF
cp /home/$HADOOP_RUN_USER/.ssh/config /root/.ssh/config

rm -rf $HADOOP_TMP_DIR $HADOOP_NAMENODE_DIR $HADOOP_DFS_DATA_DIR
mkdir -p $HADOOP_TMP_DIR $HADOOP_NAMENODE_DIR $HADOOP_DFS_DATA_DIR $HADOOP_LOG4J_DIR
chown -R $HADOOP_RUN_USER:$HADOOP_RUN_USER $HADOOP_TMP_DIR $HADOOP_NAMENODE_DIR $HADOOP_LOG4J_DIR $HADOOP_DFS_DATA_DIR /home/$HADOOP_RUN_USER

# extract hadoop source
rm -rf $HADOOP_PATH
mkdir -p $HADOOP_PATH
tar -zxf $HADOOP_SOURCE --strip-components=1 -C $HADOOP_PATH


# log folder config ugly
mkdir $HADOOP_PATH/logs

# update config
cp $HADOOP_TEMP_CONF/* $HADOOP_CONF/
for confile in $(ls $HADOOP_TEMP_CONF/); do
    sed  -i s/NAMENODE_HOSTNAME/$NAMENODE_HOSTNAME/g $HADOOP_CONF/$confile
    sed  -i s/SECNODE_HOSTNAME/$SECNODE_HOSTNAME/g $HADOOP_CONF/$confile
    sed  -i s,HADOOP_NAMENODE_DIR,$HADOOP_NAMENODE_DIR,g  $HADOOP_CONF/$confile
    sed  -i s,HADOOP_DFS_DATA_DIR,$HADOOP_DFS_DATA_DIR,g $HADOOP_CONF/$confile
    sed  -i s,HADOOP_TMP_DIR,$HADOOP_TMP_DIR,g $HADOOP_CONF/$confile
    sed  -i s,JAVAHOME,$JAVAHOME,g $HADOOP_CONF/$confile
    sed  -i s,HADOOP_ENV_NATIVE_PATH,$HADOOP_ENV_NATIVE_PATH,g $HADOOP_CONF/$confile
    sed  -i s,HADOOP_ENV_OPTS,$HADOOP_ENV_OPTS,g $HADOOP_CONF/$confile
done

# assign environment variables

cat << EVE >> /home/$HADOOP_RUN_USER/.bashrc
# add for hadoop
export JAVA_HOME=$JAVAHOME
export HADOOP_INSTALL=$HADOOP_PATH
export PATH=$PATH:$HADOOP_PATH/bin:$HADOOP_PATH/sbin
export HADOOP_MAPRED_HOME=$HADOOP_PATH
export HADOOP_COMMON_HOME=$HADOOP_PATH
export HADOOP_HDFS_HOME=$HADOOP_PATH
export YARN_HOME=$HADOOP_PATH
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_ENV_NATIVE_PATH
export HADOOP_OPTS=$HADOOP_ENV_OPTS
# end

EVE
